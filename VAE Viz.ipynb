{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100378,"status":"ok","timestamp":1681590064064,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"uV8Lch-wnW32","outputId":"94b0babb-2872-4da3-c66a-2920894c1a83"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd drive/My \\Drive/ML/"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":881},"executionInfo":{"elapsed":37138,"status":"ok","timestamp":1681590167433,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"agXdpFwPPiHw","outputId":"6ebae360-4a5f-456d-ffee-7d5be6c53e7e"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import torchvision.utils as vutils\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","import seaborn as sns\n","sns.set()\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# VAE Encoder\n","latent_dim = 100\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64 * 2, 64 * 4, 3, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","        self.fc_mu = nn.Linear(4 * 4 * 64 * 4, latent_dim)\n","        self.fc_logvar = nn.Linear(4 * 4 * 64 * 4, latent_dim)\n","\n","    def forward(self, x):\n","        x = self.main(x)\n","        x = x.view(x.size(0), -1)\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar\n","\n","# VAE Decoder\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.fc = nn.Linear(latent_dim, 4 * 4 * 64 * 4)\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(64 * 4, 64 * 2, 3, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        x = x.view(x.size(0), 64 * 4, 4, 4)\n","        x = self.main(x)\n","        return x\n","\n","# VAE\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def forward(self, x):\n","        mu, logvar = self.encoder(x)\n","        z = self.reparameterize(mu, logvar)\n","        x_reconst = self.decoder(z)\n","        return x_reconst, mu, logvar\n","\n","# MNIST dataset\n","batch_size = 128\n","image_size = 28\n","channels = 1\n","transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","mnist_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","data_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n","\n","def visualize_latent_space(model, dataloader, num_samples=1000):\n","    model.eval()\n","    latent_vectors = []\n","    labels = []\n","\n","    with torch.no_grad():\n","        for i, (images, image_labels) in enumerate(dataloader):\n","            if i * batch_size >= num_samples:\n","                break\n","            images = images.to(device)\n","            mu, _ = model.encoder(images)\n","            latent_vectors.append(mu.cpu().numpy())\n","            labels.extend(image_labels)\n","\n","    latent_vectors = np.concatenate(latent_vectors, axis=0)\n","    labels = np.array(labels)\n","    tsne = TSNE(n_components=2, random_state=0)\n","    latent_2D = tsne.fit_transform(latent_vectors)\n","\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    scatter = ax.scatter(latent_2D[:, 0], latent_2D[:, 1], c=labels, cmap='viridis', s=20, alpha=0.8)\n","    legend = ax.legend(*scatter.legend_elements(), title=\"Digits\", loc=\"upper right\", title_fontsize=12)\n","    ax.add_artist(legend)\n","    plt.title(\"Clusters of digits in VAE latent space\")\n","    plt.xlabel(\"t-SNE 1\")\n","    plt.ylabel(\"t-SNE 2\")\n","    plt.savefig('./MNIST_VAE_Clusters.png', format='png', dpi=300)\n","    plt.show()\n","\n","# Load the model\n","vae = VAE()\n","vae.load_state_dict(torch.load(\"./Weights/MNIST_VAE.pth\"))\n","vae.to(device)\n","\n","# Load a dataset with a smaller batch size for visualization\n","small_batch_size = 500\n","small_data_loader = DataLoader(mnist_data, batch_size=small_batch_size, shuffle=True)\n","\n","# Visualize the latent space\n","visualize_latent_space(vae, small_data_loader)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
