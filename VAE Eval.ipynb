{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26531,"status":"ok","timestamp":1681354334757,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"uV8Lch-wnW32","outputId":"2c3555db-e830-4d9a-d36d-ef5096b83932"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681354334757,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"Fltk46feoNyW","outputId":"eb8daf19-bc1e-42ad-abdb-a27b1f88f7f7"},"outputs":[],"source":["cd drive/My \\Drive/ML/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11513,"status":"ok","timestamp":1681354346264,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"q41YaVjL2E3Q","outputId":"9315d78f-cf4d-4538-a98e-87a304a64dab"},"outputs":[],"source":["!pip install pytorch_fid\n","!pip install POT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":888511,"status":"ok","timestamp":1681355935508,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"pcIcBleT0-z2","outputId":"8f7e69e0-eb15-4db2-bdd6-2bd1239905de"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision.models import inception_v3\n","from pytorch_fid import fid_score\n","from scipy.stats import entropy\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.transforms.functional import resize\n","import ot\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# VAE model\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64 * 2, 64 * 4, 3, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","        self.fc_mu = nn.Linear(4 * 4 * 64 * 4, latent_dim)\n","        self.fc_logvar = nn.Linear(4 * 4 * 64 * 4, latent_dim)\n","\n","    def forward(self, x):\n","        x = self.main(x)\n","        x = x.view(x.size(0), -1)\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar\n","\n","# VAE Decoder\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.fc = nn.Linear(latent_dim, 4 * 4 * 64 * 4)\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(64 * 4, 64 * 2, 3, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        x = x.view(x.size(0), 64 * 4, 4, 4)\n","        x = self.main(x)\n","        return x\n","\n","# VAE\n","latent_dim = 100\n","channels = 1\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def forward(self, x):\n","        mu, logvar = self.encoder(x)\n","        z = self.reparameterize(mu, logvar)\n","        x_reconst = self.decoder(z)\n","        return x_reconst, mu, logvar\n","\n","vae = VAE().to(device)\n","state_dict = torch.load(\"./Weights/MNIST_VAE.pth\")\n","vae.load_state_dict(state_dict)\n","generator = vae.decoder\n","\n","# Fr√©chet Inception Distance (FID)\n","print('Calculating FID')\n","def generate_fake_images(num_images):\n","    noise = torch.randn(num_images, latent_dim, device=device)\n","    fake_images = generator(noise)\n","    # Convert grayscale images to RGB by duplicating the single channel three times\n","    fake_images_rgb = fake_images.repeat(1, 3, 1, 1)\n","    return fake_images_rgb\n","\n","def extract_real_images(data_loader, num_images, save_dir=\"./data/MNIST/real_images\"):\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    real_images = []\n","    count = 0\n","    for images, _ in data_loader:\n","        for image in images:\n","            if count < num_images:\n","                torchvision.utils.save_image(image, f\"{save_dir}/image_{count}.png\")\n","                real_images.append(image)\n","                count += 1\n","            else:\n","                break\n","        if count >= num_images:\n","            break\n","\n","    return torch.stack(real_images)\n","\n","# MNIST dataset\n","batch_size = 128\n","image_size = 28\n","channels = 1\n","transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","mnist_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","data_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n","\n","print('Generating Data')\n","num_images = 1000\n","real_images = extract_real_images(data_loader, num_images)\n","fake_images = generate_fake_images(num_images)\n","\n","# Save generated images\n","os.makedirs(\"./data/MNIST/fake_images\", exist_ok=True)\n","for idx, img in enumerate(fake_images):\n","    torchvision.utils.save_image(img, f\"./data/MNIST/fake_images/image_{idx}.png\")\n","\n","def calculate_fid(real_images_path, fake_images_path, batch_size=128):\n","    dims = 2048  # Set to 2048 for Inception v3\n","    fid = fid_score.calculate_fid_given_paths([real_images_path, fake_images_path], batch_size, device, dims)\n","    return fid\n","\n","# paths for real and fake images\n","real_images_path = \"./data/MNIST/real_images\"\n","fake_images_path = \"./data/MNIST/fake_images\"\n","\n","# Calculate FID\n","fid = calculate_fid(real_images_path, fake_images_path)\n","print(\"FID:\", fid)\n","\n","# EMD\n","print('Calculating EMD')\n","print('Generating Data')\n","num_images = 1000\n","real_images = extract_real_images(data_loader, num_images)\n","fake_images = generate_fake_images(num_images)\n","# Convert fake images back to grayscale\n","fake_images = fake_images[:, 0, :, :] * 0.299 + fake_images[:, 1, :, :] * 0.587 + fake_images[:, 2, :, :] * 0.114\n","\n","def calculate_emd(real_images, fake_images):\n","    real_images = real_images.view(real_images.size(0), -1).detach().cpu().numpy()\n","    fake_images = fake_images.view(fake_images.size(0), -1).detach().cpu().numpy()\n","    cost_matrix = ot.dist(real_images, fake_images)\n","    emd = ot.emd2([], [], cost_matrix)\n","    return emd\n","emd = calculate_emd(real_images, fake_images)\n","print(\"EMD:\", emd)\n","\n","# PRF Metrics\n","print('Calculating PRF')\n","def extract_features(images, model, batch_size=32):\n","    model.eval()  # Set the model to evaluation mode\n","    images = images.to(device)  # Move images to the same device as the model\n","    \n","    # Convert grayscale images to RGB by duplicating the single channel three times\n","    images_rgb = images.repeat(1, 3, 1, 1)\n","    \n","    # Resize images to match the Inception model's input size\n","    resize_transform = transforms.Resize((299, 299))\n","    images_rgb_resized = torch.stack([resize_transform(img) for img in images_rgb])\n","\n","    num_images = len(images_rgb_resized)\n","    num_batches = (num_images + batch_size - 1) // batch_size\n","    features_list = []\n","\n","    with torch.no_grad():  # Disable gradient computation to save memory\n","        for i in range(num_batches):\n","            start_idx = i * batch_size\n","            end_idx = min(start_idx + batch_size, num_images)\n","            batch_images = images_rgb_resized[start_idx:end_idx]\n","            batch_features = model(batch_images).squeeze()\n","            features_numpy = batch_features.cpu().numpy()\n","            features_list.append(features_numpy)\n","\n","    return np.concatenate(features_list, axis=0)\n","\n","# Load pre-trained Inception v3 model\n","inception = inception_v3(pretrained=True, transform_input=True).to(device)\n","inception.eval()\n","\n","print('Generating Data')\n","fake_images = fake_images.reshape(-1,1,28,28)\n","real_features = extract_features(real_images, inception)\n","fake_features = extract_features(fake_images, inception)\n","\n","# Train a classifier\n","X = np.concatenate((real_features, fake_features))\n","y = np.concatenate((np.ones(len(real_features)), np.zeros(len(fake_features))))\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","clf = RandomForestClassifier(random_state=0, n_jobs=-1)  # n_jobs=-1 uses all available CPU cores\n","clf.fit(X_train, y_train)\n","\n","# Predict probabilities\n","y_pred_proba = clf.predict_proba(X_test)\n","\n","# Choose the probability of the positive class as the prediction score\n","y_pred_scores = y_pred_proba[:, 1]\n","\n","# Calculate precision, recall, and F1-score\n","precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_scores > 0.5, average='binary')\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1_score)\n","\n","# Inception Score (IS)\n","print('Calculating IS')\n","def generate_fake_images(num_images):\n","    noise = torch.randn(num_images, latent_dim, device=device)\n","    fake_images = generator(noise)\n","    # Convert grayscale images to RGB by duplicating the single channel three times\n","    fake_images_rgb = fake_images.repeat(1, 3, 1, 1)\n","    # Resize images to 299x299\n","    fake_images_rgb_resized = torch.zeros(num_images, 3, 299, 299, device=device)\n","    for idx, img in enumerate(fake_images_rgb):\n","        fake_images_rgb_resized[idx] = resize(img, (299, 299))\n","    return fake_images_rgb_resized\n","\n","def inception_score(images, n_splits=10):\n","    # Load pre-trained Inception model\n","    inception_model = inception_v3(pretrained=True, transform_input=True).to(device)\n","    inception_model.eval()\n","\n","    # Calculate inception score\n","    scores = []\n","    n_total = images.shape[0]\n","    chunk_size = n_total // n_splits\n","    for k in range(n_splits):\n","        images_chunk = images[k * chunk_size: (k + 1) * chunk_size]\n","        with torch.no_grad():\n","            logits = inception_model(images_chunk)\n","        p_yx = torch.softmax(logits, dim=1).cpu().numpy()\n","        p_y = np.mean(p_yx, axis=0)\n","        scores.append(entropy(p_yx).mean() - entropy(p_y))\n","    return np.exp(np.mean(scores))\n","\n","print('Generating Data')\n","fake_images = generate_fake_images(1000)\n","inception_score = inception_score(fake_images)\n","print(\"Inception Score:\", inception_score)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
